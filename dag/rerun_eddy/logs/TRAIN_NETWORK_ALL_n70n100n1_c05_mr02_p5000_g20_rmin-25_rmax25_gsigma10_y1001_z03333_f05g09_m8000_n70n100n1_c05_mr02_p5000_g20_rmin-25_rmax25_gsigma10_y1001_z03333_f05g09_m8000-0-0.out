Creating network.
The layer structure is following:
[70, 100, 1]
Setting newtork parameters
Getting training data : ALL_S6_959126400_hveto_channels_signif_dt_set_0_training.pat
Setting GA training parameters
Start running GA
Gen. 0 (0.00%): Max/Min/Avg Fitness(Raw) [25.51(66.84)/19.37(1.02)/21.26(21.26)]
Gen. 1 (5.00%): Max/Min/Avg Fitness(Raw) [35.19(72.81)/25.51(1.02)/29.32(29.32)]
Gen. 2 (10.00%): Max/Min/Avg Fitness(Raw) [32.92(79.59)/24.66(1.02)/27.44(27.44)]
Gen. 3 (15.00%): Max/Min/Avg Fitness(Raw) [35.47(82.78)/26.39(1.02)/29.56(29.56)]
Gen. 4 (20.00%): Max/Min/Avg Fitness(Raw) [36.69(84.88)/27.25(1.02)/30.58(30.58)]
Gen. 5 (25.00%): Max/Min/Avg Fitness(Raw) [35.83(87.24)/26.86(1.02)/29.86(29.86)]
Gen. 6 (30.00%): Max/Min/Avg Fitness(Raw) [40.98(90.13)/30.11(1.02)/34.15(34.15)]
Gen. 7 (35.00%): Max/Min/Avg Fitness(Raw) [39.65(90.13)/29.34(1.02)/33.05(33.05)]
Gen. 8 (40.00%): Max/Min/Avg Fitness(Raw) [39.36(91.36)/29.24(1.02)/32.80(32.80)]
Gen. 9 (45.00%): Max/Min/Avg Fitness(Raw) [39.65(91.68)/29.43(1.02)/33.04(33.04)]
Gen. 10 (50.00%): Max/Min/Avg Fitness(Raw) [45.37(92.65)/32.74(1.02)/37.81(37.81)]
Gen. 11 (55.00%): Max/Min/Avg Fitness(Raw) [46.39(94.31)/33.43(1.02)/38.66(38.66)]
Gen. 12 (60.00%): Max/Min/Avg Fitness(Raw) [44.63(94.77)/32.52(1.02)/37.19(37.19)]
Gen. 13 (65.00%): Max/Min/Avg Fitness(Raw) [47.46(94.87)/34.04(1.02)/39.55(39.55)]
Gen. 14 (70.00%): Max/Min/Avg Fitness(Raw) [50.63(96.21)/35.76(1.02)/42.19(42.19)]
Gen. 15 (75.00%): Max/Min/Avg Fitness(Raw) [52.16(98.75)/36.79(1.02)/43.47(43.47)]
Gen. 16 (80.00%): Max/Min/Avg Fitness(Raw) [50.53(98.75)/36.00(1.02)/42.11(42.11)]
Gen. 17 (85.00%): Max/Min/Avg Fitness(Raw) [52.03(99.44)/36.81(1.02)/43.36(43.36)]
Gen. 18 (90.00%): Max/Min/Avg Fitness(Raw) [50.77(99.44)/36.19(1.02)/42.31(42.31)]
Gen. 19 (95.00%): Max/Min/Avg Fitness(Raw) [51.56(99.44)/36.58(1.02)/42.97(42.97)]
Gen. 20 (100.00%): Max/Min/Avg Fitness(Raw) [51.09(99.44)/36.35(1.02)/42.58(42.58)]
Total time elapsed: 81628.569 seconds.
GA MSE : 0.012482
Best initial connection wetighs are set on Network
Setting FANN training parameters
Input layer                          :  70 neurons, 1 bias
  Hidden layer                       : 100 neurons, 1 bias
Output layer                         :   1 neurons
Total neurons and biases             : 173
Total connections                    :3701
Connection rate                      :   0.500
Network type                         :   FANN_NETTYPE_LAYER
Training algorithm                   :   FANN_TRAIN_RPROP
Training error function              :   FANN_ERRORFUNC_TANH
Training stop function               :   FANN_STOPFUNC_MSE
Bit fail limit                       :   0.350
Learning rate                        :   0.700
Learning momentum                    :   0.000
Quickprop decay                      :  -0.000100
Quickprop mu                         :   1.750
RPROP increase factor                :   1.001
RPROP decrease factor                :   0.333
RPROP delta min                      :   0.000
RPROP delta max                      :  50.000
Cascade output change fraction       :   0.010000
Cascade candidate change fraction    :   0.010000
Cascade output stagnation epochs     :  12
Cascade candidate stagnation epochs  :  12
Cascade max output epochs            : 150
Cascade max candidate epochs         : 150
Cascade weight multiplier            :   0.400
Cascade candidate limit              :1000.000
Cascade activation functions[0]      :   FANN_SIGMOID
Cascade activation functions[1]      :   FANN_SIGMOID_SYMMETRIC
Cascade activation functions[2]      :   FANN_GAUSSIAN
Cascade activation functions[3]      :   FANN_GAUSSIAN_SYMMETRIC
Cascade activation functions[4]      :   FANN_ELLIOT
Cascade activation functions[5]      :   FANN_ELLIOT_SYMMETRIC
Cascade activation functions[6]      :   FANN_SIN_SYMMETRIC
Cascade activation functions[7]      :   FANN_COS_SYMMETRIC
Cascade activation functions[8]      :   FANN_SIN
Cascade activation functions[9]      :   FANN_COS
Cascade activation steepnesses[0]    :   0.250
Cascade activation steepnesses[1]    :   0.500
Cascade activation steepnesses[2]    :   0.750
Cascade activation steepnesses[3]    :   1.000
Cascade candidate groups             :   2
Cascade no. of candidates            :  80
Start training network with 2-algorithm in FANN
Max epochs     8000. Desired error: 0.0010000000.
Epochs            1. Current error: 0.0100561827. Bit fail 184.
Epochs          100. Current error: 0.0107044242. Bit fail 212.
Epochs          200. Current error: 0.0101581588. Bit fail 213.
Epochs          300. Current error: 0.0094786892. Bit fail 196.
Epochs          400. Current error: 0.0090813097. Bit fail 194.
Epochs          500. Current error: 0.0087470729. Bit fail 190.
Epochs          600. Current error: 0.0086233560. Bit fail 186.
Epochs          700. Current error: 0.0084343953. Bit fail 174.
Epochs          800. Current error: 0.0083187101. Bit fail 175.
Epochs          900. Current error: 0.0082522174. Bit fail 173.
Epochs         1000. Current error: 0.0081750406. Bit fail 172.
Epochs         1100. Current error: 0.0080892323. Bit fail 171.
Epochs         1200. Current error: 0.0079805804. Bit fail 176.
Epochs         1300. Current error: 0.0078471182. Bit fail 174.
Epochs         1400. Current error: 0.0077299634. Bit fail 173.
Epochs         1500. Current error: 0.0076474906. Bit fail 169.
Epochs         1600. Current error: 0.0075516435. Bit fail 167.
Epochs         1700. Current error: 0.0074258894. Bit fail 164.
Epochs         1800. Current error: 0.0073371525. Bit fail 161.
Epochs         1900. Current error: 0.0072655608. Bit fail 160.
Epochs         2000. Current error: 0.0071561281. Bit fail 160.
Epochs         2100. Current error: 0.0071191918. Bit fail 159.
Epochs         2200. Current error: 0.0071417182. Bit fail 158.
Epochs         2300. Current error: 0.0071306550. Bit fail 156.
Epochs         2400. Current error: 0.0071306801. Bit fail 154.
Epochs         2500. Current error: 0.0071120188. Bit fail 153.
Epochs         2600. Current error: 0.0070653502. Bit fail 151.
Epochs         2700. Current error: 0.0070387819. Bit fail 149.
Epochs         2800. Current error: 0.0070111575. Bit fail 151.
Epochs         2900. Current error: 0.0069594523. Bit fail 150.
Epochs         3000. Current error: 0.0069047417. Bit fail 146.
Epochs         3100. Current error: 0.0068462892. Bit fail 151.
Epochs         3200. Current error: 0.0067980425. Bit fail 147.
Epochs         3300. Current error: 0.0067292568. Bit fail 145.
Epochs         3400. Current error: 0.0066887108. Bit fail 143.
Epochs         3500. Current error: 0.0066033262. Bit fail 143.
Epochs         3600. Current error: 0.0065687429. Bit fail 143.
Epochs         3700. Current error: 0.0064683752. Bit fail 141.
Epochs         3800. Current error: 0.0064147366. Bit fail 144.
Epochs         3900. Current error: 0.0063175424. Bit fail 144.
Epochs         4000. Current error: 0.0062315040. Bit fail 141.
Epochs         4100. Current error: 0.0061883116. Bit fail 139.
Epochs         4200. Current error: 0.0061750119. Bit fail 138.
Epochs         4300. Current error: 0.0061494289. Bit fail 136.
Epochs         4400. Current error: 0.0061210711. Bit fail 136.
Epochs         4500. Current error: 0.0060852212. Bit fail 136.
Epochs         4600. Current error: 0.0060440451. Bit fail 131.
Epochs         4700. Current error: 0.0060131093. Bit fail 129.
Epochs         4800. Current error: 0.0059747146. Bit fail 126.
Epochs         4900. Current error: 0.0059469058. Bit fail 125.
Epochs         5000. Current error: 0.0059340326. Bit fail 126.
Epochs         5100. Current error: 0.0059129344. Bit fail 122.
Epochs         5200. Current error: 0.0059931446. Bit fail 123.
Epochs         5300. Current error: 0.0059277583. Bit fail 121.
Epochs         5400. Current error: 0.0058496115. Bit fail 120.
Epochs         5500. Current error: 0.0058348463. Bit fail 118.
Epochs         5600. Current error: 0.0058127451. Bit fail 119.
Epochs         5700. Current error: 0.0058078091. Bit fail 119.
Epochs         5800. Current error: 0.0057905810. Bit fail 117.
Epochs         5900. Current error: 0.0057706293. Bit fail 118.
Epochs         6000. Current error: 0.0057445355. Bit fail 119.
Epochs         6100. Current error: 0.0057013961. Bit fail 117.
Epochs         6200. Current error: 0.0056858091. Bit fail 117.
Epochs         6300. Current error: 0.0056710592. Bit fail 115.
Epochs         6400. Current error: 0.0056699044. Bit fail 113.
Epochs         6500. Current error: 0.0056681717. Bit fail 114.
Epochs         6600. Current error: 0.0056544212. Bit fail 113.
Epochs         6700. Current error: 0.0056370739. Bit fail 114.
Epochs         6800. Current error: 0.0056312717. Bit fail 113.
Epochs         6900. Current error: 0.0056325337. Bit fail 113.
Epochs         7000. Current error: 0.0058273911. Bit fail 114.
Epochs         7100. Current error: 0.0059771128. Bit fail 113.
Epochs         7200. Current error: 0.0059536784. Bit fail 113.
Epochs         7300. Current error: 0.0059353611. Bit fail 116.
Epochs         7400. Current error: 0.0059161913. Bit fail 114.
Epochs         7500. Current error: 0.0058992831. Bit fail 113.
Epochs         7600. Current error: 0.0058815652. Bit fail 113.
Epochs         7700. Current error: 0.0058777216. Bit fail 112.
Epochs         7800. Current error: 0.0058702230. Bit fail 113.
Epochs         7900. Current error: 0.0058600381. Bit fail 115.
Epochs         8000. Current error: 0.0058459486. Bit fail 113.
Time elpased for FANN training: 2578.379952 seconds
Trained Network by GA+FANN is saved in 
./ALL_S6_959126400_hveto_channels_signif_dt_set_0_training_n70n100n1_c05_mr02_p5000_g20_rmin-25_rmax25_gsigma10_y1001_z03333_f05g09_m8000.net.
Total Running Time: 84207.749824 seconds
