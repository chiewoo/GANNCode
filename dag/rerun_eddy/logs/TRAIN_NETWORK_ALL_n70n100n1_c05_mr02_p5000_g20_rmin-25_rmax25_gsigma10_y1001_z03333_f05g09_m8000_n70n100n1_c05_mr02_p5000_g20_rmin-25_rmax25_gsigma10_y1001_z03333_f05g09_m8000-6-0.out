Creating network.
The layer structure is following:
[70, 100, 1]
Setting newtork parameters
Getting training data : ALL_S6_959126400_hveto_channels_signif_dt_set_3_training.pat
Setting GA training parameters
Start running GA
Gen. 0 (0.00%): Max/Min/Avg Fitness(Raw) [24.86(59.78)/18.63(1.02)/20.72(20.72)]
Gen. 1 (5.00%): Max/Min/Avg Fitness(Raw) [35.45(68.94)/25.26(1.02)/29.54(29.54)]
Gen. 2 (10.00%): Max/Min/Avg Fitness(Raw) [33.00(74.93)/24.43(1.02)/27.50(27.50)]
Gen. 3 (15.00%): Max/Min/Avg Fitness(Raw) [44.41(79.45)/30.73(1.02)/37.01(37.01)]
Gen. 4 (20.00%): Max/Min/Avg Fitness(Raw) [43.66(86.13)/31.21(1.02)/36.38(36.38)]
Gen. 5 (25.00%): Max/Min/Avg Fitness(Raw) [45.22(91.70)/32.57(1.02)/37.68(37.68)]
Gen. 6 (30.00%): Max/Min/Avg Fitness(Raw) [48.21(93.17)/34.24(1.02)/40.17(40.17)]
Gen. 7 (35.00%): Max/Min/Avg Fitness(Raw) [50.77(96.47)/35.86(1.02)/42.31(42.31)]
Gen. 8 (40.00%): Max/Min/Avg Fitness(Raw) [51.86(98.95)/36.67(1.02)/43.21(43.21)]
Gen. 9 (45.00%): Max/Min/Avg Fitness(Raw) [46.97(100.39)/34.27(1.02)/39.14(39.14)]
Gen. 10 (50.00%): Max/Min/Avg Fitness(Raw) [49.04(102.35)/35.57(1.02)/40.87(40.87)]
Gen. 11 (55.00%): Max/Min/Avg Fitness(Raw) [49.31(102.35)/35.72(1.02)/41.09(41.09)]
Gen. 12 (60.00%): Max/Min/Avg Fitness(Raw) [48.47(103.92)/35.39(1.02)/40.39(40.39)]
Gen. 13 (65.00%): Max/Min/Avg Fitness(Raw) [48.59(103.92)/35.45(1.02)/40.49(40.49)]
Gen. 14 (70.00%): Max/Min/Avg Fitness(Raw) [50.54(104.64)/36.58(1.02)/42.12(42.12)]
Gen. 15 (75.00%): Max/Min/Avg Fitness(Raw) [48.73(105.03)/35.62(1.02)/40.60(40.60)]
Gen. 16 (80.00%): Max/Min/Avg Fitness(Raw) [48.64(106.21)/35.66(1.02)/40.53(40.53)]
Gen. 17 (85.00%): Max/Min/Avg Fitness(Raw) [46.15(106.21)/34.21(1.02)/38.46(38.46)]
Gen. 18 (90.00%): Max/Min/Avg Fitness(Raw) [47.36(106.77)/34.96(1.02)/39.47(39.47)]
Gen. 19 (95.00%): Max/Min/Avg Fitness(Raw) [46.99(106.86)/34.75(1.02)/39.16(39.16)]
Gen. 20 (100.00%): Max/Min/Avg Fitness(Raw) [46.85(106.86)/34.67(1.02)/39.04(39.04)]
Total time elapsed: 81245.186 seconds.
GA MSE : 0.976644
Best initial connection wetighs are set on Network
Setting FANN training parameters
Input layer                          :  70 neurons, 1 bias
  Hidden layer                       : 100 neurons, 1 bias
Output layer                         :   1 neurons
Total neurons and biases             : 173
Total connections                    :3701
Connection rate                      :   0.500
Network type                         :   FANN_NETTYPE_LAYER
Training algorithm                   :   FANN_TRAIN_RPROP
Training error function              :   FANN_ERRORFUNC_TANH
Training stop function               :   FANN_STOPFUNC_MSE
Bit fail limit                       :   0.350
Learning rate                        :   0.700
Learning momentum                    :   0.000
Quickprop decay                      :  -0.000100
Quickprop mu                         :   1.750
RPROP increase factor                :   1.001
RPROP decrease factor                :   0.333
RPROP delta min                      :   0.000
RPROP delta max                      :  50.000
Cascade output change fraction       :   0.010000
Cascade candidate change fraction    :   0.010000
Cascade output stagnation epochs     :  12
Cascade candidate stagnation epochs  :  12
Cascade max output epochs            : 150
Cascade max candidate epochs         : 150
Cascade weight multiplier            :   0.400
Cascade candidate limit              :1000.000
Cascade activation functions[0]      :   FANN_SIGMOID
Cascade activation functions[1]      :   FANN_SIGMOID_SYMMETRIC
Cascade activation functions[2]      :   FANN_GAUSSIAN
Cascade activation functions[3]      :   FANN_GAUSSIAN_SYMMETRIC
Cascade activation functions[4]      :   FANN_ELLIOT
Cascade activation functions[5]      :   FANN_ELLIOT_SYMMETRIC
Cascade activation functions[6]      :   FANN_SIN_SYMMETRIC
Cascade activation functions[7]      :   FANN_COS_SYMMETRIC
Cascade activation functions[8]      :   FANN_SIN
Cascade activation functions[9]      :   FANN_COS
Cascade activation steepnesses[0]    :   0.250
Cascade activation steepnesses[1]    :   0.500
Cascade activation steepnesses[2]    :   0.750
Cascade activation steepnesses[3]    :   1.000
Cascade candidate groups             :   2
Cascade no. of candidates            :  80
Start training network with 2-algorithm in FANN
Max epochs     8000. Desired error: 0.0010000000.
Epochs            1. Current error: 0.0093577774. Bit fail 169.
Epochs          100. Current error: 0.0102316476. Bit fail 199.
Epochs          200. Current error: 0.0096276570. Bit fail 200.
Epochs          300. Current error: 0.0091319550. Bit fail 193.
Epochs          400. Current error: 0.0088039944. Bit fail 188.
Epochs          500. Current error: 0.0085182926. Bit fail 178.
Epochs          600. Current error: 0.0083689447. Bit fail 175.
Epochs          700. Current error: 0.0081960829. Bit fail 174.
Epochs          800. Current error: 0.0080473693. Bit fail 170.
Epochs          900. Current error: 0.0078970650. Bit fail 167.
Epochs         1000. Current error: 0.0077792569. Bit fail 168.
Epochs         1100. Current error: 0.0076631177. Bit fail 161.
Epochs         1200. Current error: 0.0075902087. Bit fail 159.
Epochs         1300. Current error: 0.0074557965. Bit fail 155.
Epochs         1400. Current error: 0.0073833517. Bit fail 153.
Epochs         1500. Current error: 0.0073118727. Bit fail 148.
Epochs         1600. Current error: 0.0072293235. Bit fail 148.
Epochs         1700. Current error: 0.0071682371. Bit fail 146.
Epochs         1800. Current error: 0.0070855883. Bit fail 148.
Epochs         1900. Current error: 0.0070277150. Bit fail 147.
Epochs         2000. Current error: 0.0069053401. Bit fail 148.
Epochs         2100. Current error: 0.0067784553. Bit fail 143.
Epochs         2200. Current error: 0.0066669965. Bit fail 139.
Epochs         2300. Current error: 0.0065148966. Bit fail 134.
Epochs         2400. Current error: 0.0064353896. Bit fail 136.
Epochs         2500. Current error: 0.0063565001. Bit fail 134.
Epochs         2600. Current error: 0.0062874467. Bit fail 128.
Epochs         2700. Current error: 0.0062394263. Bit fail 126.
Epochs         2800. Current error: 0.0062048030. Bit fail 124.
Epochs         2900. Current error: 0.0061675431. Bit fail 121.
Epochs         3000. Current error: 0.0061498038. Bit fail 119.
Epochs         3100. Current error: 0.0061207218. Bit fail 120.
Epochs         3200. Current error: 0.0060656494. Bit fail 123.
Epochs         3300. Current error: 0.0060381689. Bit fail 123.
Epochs         3400. Current error: 0.0060097594. Bit fail 118.
Epochs         3500. Current error: 0.0059625176. Bit fail 116.
Epochs         3600. Current error: 0.0059089167. Bit fail 118.
Epochs         3700. Current error: 0.0058959741. Bit fail 116.
Epochs         3800. Current error: 0.0058849058. Bit fail 116.
Epochs         3900. Current error: 0.0058616223. Bit fail 114.
Epochs         4000. Current error: 0.0058502299. Bit fail 116.
Epochs         4100. Current error: 0.0058398391. Bit fail 118.
Epochs         4200. Current error: 0.0058152201. Bit fail 117.
Epochs         4300. Current error: 0.0057655331. Bit fail 117.
Epochs         4400. Current error: 0.0057346262. Bit fail 113.
Epochs         4500. Current error: 0.0057075545. Bit fail 113.
Epochs         4600. Current error: 0.0056832558. Bit fail 111.
Epochs         4700. Current error: 0.0056512249. Bit fail 112.
Epochs         4800. Current error: 0.0056067202. Bit fail 113.
Epochs         4900. Current error: 0.0055685155. Bit fail 112.
Epochs         5000. Current error: 0.0055444115. Bit fail 112.
Epochs         5100. Current error: 0.0055253776. Bit fail 111.
Epochs         5200. Current error: 0.0055027939. Bit fail 109.
Epochs         5300. Current error: 0.0054835607. Bit fail 110.
Epochs         5400. Current error: 0.0054702437. Bit fail 110.
Epochs         5500. Current error: 0.0054517938. Bit fail 108.
Epochs         5600. Current error: 0.0054931683. Bit fail 106.
Epochs         5700. Current error: 0.0054727485. Bit fail 106.
Epochs         5800. Current error: 0.0054541361. Bit fail 105.
Epochs         5900. Current error: 0.0054283114. Bit fail 106.
Epochs         6000. Current error: 0.0054015419. Bit fail 105.
Epochs         6100. Current error: 0.0053421371. Bit fail 104.
Epochs         6200. Current error: 0.0053248405. Bit fail 102.
Epochs         6300. Current error: 0.0053061182. Bit fail 102.
Epochs         6400. Current error: 0.0053456221. Bit fail 103.
Epochs         6500. Current error: 0.0053237844. Bit fail 103.
Epochs         6600. Current error: 0.0053095729. Bit fail 103.
Epochs         6700. Current error: 0.0052938396. Bit fail 103.
Epochs         6800. Current error: 0.0052827895. Bit fail 103.
Epochs         6900. Current error: 0.0052734097. Bit fail 104.
Epochs         7000. Current error: 0.0052713151. Bit fail 103.
Epochs         7100. Current error: 0.0052564032. Bit fail 103.
Epochs         7200. Current error: 0.0052441638. Bit fail 103.
Epochs         7300. Current error: 0.0052277525. Bit fail 103.
Epochs         7400. Current error: 0.0051785638. Bit fail 101.
Epochs         7500. Current error: 0.0051649748. Bit fail 99.
Epochs         7600. Current error: 0.0051534530. Bit fail 99.
Epochs         7700. Current error: 0.0051401271. Bit fail 100.
Epochs         7800. Current error: 0.0051306412. Bit fail 101.
Epochs         7900. Current error: 0.0051208902. Bit fail 101.
Epochs         8000. Current error: 0.0051165586. Bit fail 101.
Time elpased for FANN training: 2547.280537 seconds
Trained Network by GA+FANN is saved in 
./ALL_S6_959126400_hveto_channels_signif_dt_set_3_training_n70n100n1_c05_mr02_p5000_g20_rmin-25_rmax25_gsigma10_y1001_z03333_f05g09_m8000.net.
Total Running Time: 83793.811368 seconds
